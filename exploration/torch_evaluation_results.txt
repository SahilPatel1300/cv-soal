=== PyTorch Model Evaluation ===
Dataset path: ../../dexnet_2.1/dexnet_2.1_eps_10/tensors/
Timestamp: 2025-04-21 03:18:31

Using device: cuda
Found 17 tensor files

Processing 5 files...

Processing file 1/5...
File contains 1000 samples
Running inference on 32 batches...
Processed 1000 samples from file 1

Processing file 2/5...
File contains 1000 samples
Running inference on 32 batches...
Processed 1000 samples from file 2

Processing file 3/5...
File contains 1000 samples
Running inference on 32 batches...
Processed 1000 samples from file 3

Processing file 4/5...
File contains 1000 samples
Running inference on 32 batches...
Processed 1000 samples from file 4

Processing file 5/5...
File contains 1000 samples
Running inference on 32 batches...
Processed 1000 samples from file 5

===============================================
1. BASIC STATISTICS
===============================================
Total samples evaluated: 1472
Positive samples: 736 (50.00%)
Negative samples: 736 (50.00%)

>> Prediction Score Distribution <<
Mean prediction: 0.4249
Median prediction: 0.5570
Standard deviation: 0.3033
Min prediction: 0.0000
Max prediction: 0.9415
25th percentile: 0.0459
75th percentile: 0.6840

===============================================
2. CLASSIFICATION METRICS (at threshold=0.5)
===============================================
True Positives: 640 - (Correct positive predictions)
True Negatives: 582 - (Correct negative predictions)
False Positives: 154 - (Type I error; predicted positive but actually negative)
False Negatives: 96 - (Type II error; predicted negative but actually positive)

>> Standard Classification Metrics <<
Accuracy: 0.8302 - (Proportion of correct predictions)
Precision: 0.8060 - (TP/(TP+FP); proportion of positive predictions that are correct)
Recall/Sensitivity: 0.8696 - (TP/(TP+FN); proportion of actual positives correctly identified)
Specificity: 0.7908 - (TN/(TN+FP); proportion of actual negatives correctly identified)
F1 Score: 0.8366 - (Harmonic mean of precision and recall)
Balanced Accuracy: 0.8302 - (Average of recall and specificity)

===============================================
3. THRESHOLD OPTIMIZATION
===============================================
Optimal threshold (maximizing F1): 0.2657
F1 score at optimal threshold: 0.8514

>> Metrics at Optimal Threshold <<
Accuracy: 0.8288
Precision: 0.7542
Recall/Sensitivity: 0.9755
Specificity: 0.6821

===============================================
4. RANKING & DISCRIMINATION METRICS
===============================================
ROC AUC: 0.8943 - (Area under ROC curve; probability that a random positive is ranked higher than a random negative)
PR AUC (Average Precision): 0.8607 - (Area under precision-recall curve; summary of precision at different recall levels)
Log Loss: 0.3995 - (Cross-entropy loss; lower is better)

===============================================
6. VISUALIZATION SUMMARY
===============================================
Generated visualizations:
  1. roc_curve.png
  2. pr_curve.png
  3. confusion_matrix.png