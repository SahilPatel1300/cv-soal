{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8d2af01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# setup cell to make our lives easier \n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from utils import *\n",
    "from eval_script import *\n",
    "from customize_dataset import DexNetNPZDataset\n",
    "from customize_dataset import DexNetNPZDatasetAll\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "tensor_dir = '../../dexnet_2.1/dexnet_2.1_eps_50/tensors/'  # replace with actual path\n",
    "batch_size = 32\n",
    "use_regression = False  # or True\n",
    "pose_dims = [2]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da4b14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup block. Run me!\n",
    "#print(torch.cuda.device_count())\n",
    "#print(torch.cuda.get_device_name())\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90c72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_with_confusion(model, dataloader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Initialize confusion matrix counts\n",
    "    TP = FP = TN = FN = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, poses, labels in dataloader:\n",
    "            images = images.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
    "            poses = poses.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True).unsqueeze(1)\n",
    "\n",
    "            outputs = model(images, poses)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            predictions = (outputs >= threshold).float()\n",
    "\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Compute confusion matrix components\n",
    "            TP += ((predictions == 1) & (labels == 1)).sum().item()\n",
    "            TN += ((predictions == 0) & (labels == 0)).sum().item()\n",
    "            FP += ((predictions == 1) & (labels == 0)).sum().item()\n",
    "            FN += ((predictions == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Normalize confusion matrix to percentage\n",
    "    percent = lambda x: (x / total) * 100\n",
    "    confusion_matrix = [\n",
    "        [percent(TN), percent(FP)],  # row for actual 0\n",
    "        [percent(FN), percent(TP)]   # row for actual 1\n",
    "    ]\n",
    "\n",
    "    print(f\"âœ… Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"ðŸ“Š Confusion Matrix (in %):\")\n",
    "    print(f\"            Pred 0     Pred 1\")\n",
    "    print(f\"Actual 0   {confusion_matrix[0][0]:6.2f}%   {confusion_matrix[0][1]:6.2f}%\")\n",
    "    print(f\"Actual 1   {confusion_matrix[1][0]:6.2f}%   {confusion_matrix[1][1]:6.2f}%\")\n",
    "\n",
    "    return accuracy, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727f20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGQCNN(nn.Module):\n",
    "    def __init__(self, pose_dim=4, output_type='binary', merge_methods=\"element_dot\"):\n",
    "        \"\"\"\n",
    "        pose_dim: number of dimensions in the pose vector (e.g., x, y, z, theta)\n",
    "        output_type: 'binary' or 'regression'\n",
    "        \"\"\"\n",
    "        super(SimpleGQCNN, self).__init__()\n",
    "        self.output_type = output_type\n",
    "\n",
    "        # Image stream\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)           # â†’ (B, 16, 30, 30)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             # â†’ (B, 16, 15, 15)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)          # â†’ (B, 32, 13, 13) â†’ pool â†’ (B, 32, 6, 6)\n",
    "        self.im_fc = nn.Linear(32 * 6 * 6, 64)     # â†’ (B, 64)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.im_fc_bn = nn.BatchNorm1d(64)\n",
    "\n",
    "        # Pose stream\n",
    "        self.pose_fc1 = nn.Linear(pose_dim, 64)\n",
    "        self.pose_fc2 = nn.Linear(64, 64)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.merge_methods = merge_methods\n",
    "        if self.merge_methods == \"element_dot\":\n",
    "            # Merge stream after elementwise multiplication\n",
    "            self.merge_fc1 = nn.Linear(64, 32)\n",
    "            self.merge_fc2 = nn.Linear(32, 1)\n",
    "        else:\n",
    "            # Merge stream by concatanation\n",
    "            self.merge_fc1 = nn.Linear(64 + 64, 64)\n",
    "            self.merge_fc2 = nn.Linear(64, 1)  # Single output for binary or regression\n",
    "\n",
    "    def forward(self, image, pose):\n",
    "        \n",
    "        # Image stream\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(image))))   # (B, 16, 15, 15)\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))       # (B, 32, 6, 6)\n",
    "        # x = x.view(x.size(0), -1)                  # Flatten\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.im_fc(x))                  # (B, 64)\n",
    "\n",
    "        # Pose stream\n",
    "        p = self.dropout(F.relu(self.pose_fc1(pose)))            # (B, 64)\n",
    "        p = self.dropout(F.relu(self.pose_fc2(p)))               # (B, 64)\n",
    "\n",
    "        if self.merge_methods == \"element_dot\":\n",
    "            # Element-wise multiplication\n",
    "            combined = x * p                           # (B, 64)\n",
    "        else:\n",
    "            # Merge\n",
    "            combined = torch.cat((x, p), dim=1)       # -> (B, 96)\n",
    "\n",
    "        # Final layers\n",
    "        out = F.relu(self.merge_fc1(combined))     # (B, 32)\n",
    "        out = self.merge_fc2(out)                  # (B, 1)\n",
    "\n",
    "        # if self.output_type == 'binary':\n",
    "        #     out = torch.sigmoid(out)               # Binary prediction\n",
    "        return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11d25ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SimpleGQCNN\n",
    "pose_dims = [0, 1, 2, 3, 4, 5]\n",
    "model = SimpleGQCNN(pose_dim=len(pose_dims), output_type='regression' if use_regression else 'binary')\n",
    "model.load_state_dict(torch.load(\"eps_50/model.pth\", weights_only=False, map_location=torch.device('cpu')))\n",
    "model = model.to(device, memory_format=torch.channels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd2d8bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 35 tensor files\n",
      "\n",
      "Processing 5 files...\n",
      "\n",
      "Processing file 1/5...\n",
      "File contains 1000 samples\n",
      "Running inference on 32 batches...\n",
      "Processed 1000 samples from file 1\n",
      "\n",
      "Processing file 2/5...\n",
      "File contains 1000 samples\n",
      "Running inference on 32 batches...\n",
      "Processed 1000 samples from file 2\n",
      "\n",
      "Processing file 3/5...\n",
      "File contains 1000 samples\n",
      "Running inference on 32 batches...\n",
      "Processed 1000 samples from file 3\n",
      "\n",
      "Processing file 4/5...\n",
      "File contains 1000 samples\n",
      "Running inference on 32 batches...\n",
      "Processed 1000 samples from file 4\n",
      "\n",
      "Processing file 5/5...\n",
      "File contains 1000 samples\n",
      "Running inference on 32 batches...\n",
      "Processed 1000 samples from file 5\n",
      "\n",
      "Model evaluation complete! Results saved to 'torch_evaluation_results.txt'\n",
      "Visualizations saved to directory: './torch_evaluation_plots_ep10'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.7722161 , 0.89610803, 0.10588651, ..., 0.6362017 , 0.6697744 ,\n",
       "        0.01269574], shape=(5000,), dtype=float32),\n",
       " array([1, 1, 0, ..., 0, 0, 0], shape=(5000,)),\n",
       " array([0.00646952, 0.01583533, 0.0013913 , ..., 0.        , 0.00047008,\n",
       "        0.        ], shape=(5000,)))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_dir = \"../../dexnet_2.1/dexnet_2.1_eps_50/tensors/\"\n",
    "pose_dims = [0, 1, 2, 3, 4, 5]\n",
    "run_model_evaluation(\n",
    "    model=model,\n",
    "    tensor_dir=tensor_dir,\n",
    "    batch_size=batch_size,\n",
    "    pose_dims=pose_dims,\n",
    "    visualizations_dir=\"./torch_evaluation_plots_ep10\",\n",
    "    use_regression=use_regression,\n",
    "    num_files=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f063d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 68.75%\n",
      "ðŸ“Š Confusion Matrix (in %):\n",
      "            Pred 0     Pred 1\n",
      "Actual 0    31.25%    30.63%\n",
      "Actual 1     0.62%    37.50%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6875, [[31.25, 30.625000000000004], [0.625, 37.5]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "# Create dataset and dataloader\n",
    "train_loader, val_loader = DexNetDataloader(tensor_dir=tensor_dir, use_regression=use_regression, pose_dims=pose_dims)\n",
    " \n",
    "subset_loader = itertools.islice(val_loader, 5)  # Use only the first 5 batches\n",
    "\n",
    "evaluate_accuracy_with_confusion(model, subset_loader, device, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724bfc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(r\"..\\..\\dexnet_2.1\\corl2017_experiments\\tensors\\domain_label_00000.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b51d662a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
