{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d2af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# setup cell to make our lives easier \n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from utils import *\n",
    "from customize_dataset import DexNetNPZDataset\n",
    "from customize_dataset import DexNetNPZDatasetAll\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "tensor_dir = '../../dexnet_2.1/dexnet_2.1_eps_10/tensors/'  # replace with actual path\n",
    "batch_size = 32\n",
    "use_regression = False  # or True\n",
    "pose_dims = [2]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da4b14cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# setup block. Run me!\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90c72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_with_confusion(model, dataloader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Initialize confusion matrix counts\n",
    "    TP = FP = TN = FN = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, poses, labels in dataloader:\n",
    "            images = images.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
    "            poses = poses.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True).unsqueeze(1)\n",
    "\n",
    "            outputs = model(images, poses)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            predictions = (outputs >= threshold).float()\n",
    "\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Compute confusion matrix components\n",
    "            TP += ((predictions == 1) & (labels == 1)).sum().item()\n",
    "            TN += ((predictions == 0) & (labels == 0)).sum().item()\n",
    "            FP += ((predictions == 1) & (labels == 0)).sum().item()\n",
    "            FN += ((predictions == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Normalize confusion matrix to percentage\n",
    "    percent = lambda x: (x / total) * 100\n",
    "    confusion_matrix = [\n",
    "        [percent(TN), percent(FP)],  # row for actual 0\n",
    "        [percent(FN), percent(TP)]   # row for actual 1\n",
    "    ]\n",
    "\n",
    "    print(f\"âœ… Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"ðŸ“Š Confusion Matrix (in %):\")\n",
    "    print(f\"            Pred 0     Pred 1\")\n",
    "    print(f\"Actual 0   {confusion_matrix[0][0]:6.2f}%   {confusion_matrix[0][1]:6.2f}%\")\n",
    "    print(f\"Actual 1   {confusion_matrix[1][0]:6.2f}%   {confusion_matrix[1][1]:6.2f}%\")\n",
    "\n",
    "    return accuracy, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727f20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGQCNN(nn.Module):\n",
    "    def __init__(self, pose_dim=4, output_type='binary', merge_methods=\"element_dot\"):\n",
    "        \"\"\"\n",
    "        pose_dim: number of dimensions in the pose vector (e.g., x, y, z, theta)\n",
    "        output_type: 'binary' or 'regression'\n",
    "        \"\"\"\n",
    "        super(SimpleGQCNN, self).__init__()\n",
    "        self.output_type = output_type\n",
    "\n",
    "        # Image stream\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)           # â†’ (B, 16, 30, 30)\n",
    "        self.pool = nn.MaxPool2d(2, 2)             # â†’ (B, 16, 15, 15)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)          # â†’ (B, 32, 13, 13) â†’ pool â†’ (B, 32, 6, 6)\n",
    "        self.im_fc = nn.Linear(32 * 6 * 6, 64)     # â†’ (B, 64)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.im_fc_bn = nn.BatchNorm1d(64)\n",
    "\n",
    "        # Pose stream\n",
    "        self.pose_fc1 = nn.Linear(pose_dim, 64)\n",
    "        self.pose_fc2 = nn.Linear(64, 64)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.merge_methods = merge_methods\n",
    "        if self.merge_methods == \"element_dot\":\n",
    "            # Merge stream after elementwise multiplication\n",
    "            self.merge_fc1 = nn.Linear(64, 32)\n",
    "            self.merge_fc2 = nn.Linear(32, 1)\n",
    "        else:\n",
    "            # Merge stream by concatanation\n",
    "            self.merge_fc1 = nn.Linear(64 + 64, 64)\n",
    "            self.merge_fc2 = nn.Linear(64, 1)  # Single output for binary or regression\n",
    "\n",
    "    def forward(self, image, pose):\n",
    "        \n",
    "        # Image stream\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(image))))   # (B, 16, 15, 15)\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))       # (B, 32, 6, 6)\n",
    "        # x = x.view(x.size(0), -1)                  # Flatten\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.im_fc(x))                  # (B, 64)\n",
    "\n",
    "        # Pose stream\n",
    "        p = self.dropout(F.relu(self.pose_fc1(pose)))            # (B, 64)\n",
    "        p = self.dropout(F.relu(self.pose_fc2(p)))               # (B, 64)\n",
    "\n",
    "        if self.merge_methods == \"element_dot\":\n",
    "            # Element-wise multiplication\n",
    "            combined = x * p                           # (B, 64)\n",
    "        else:\n",
    "            # Merge\n",
    "            combined = torch.cat((x, p), dim=1)       # -> (B, 96)\n",
    "\n",
    "        # Final layers\n",
    "        out = F.relu(self.merge_fc1(combined))     # (B, 32)\n",
    "        out = self.merge_fc2(out)                  # (B, 1)\n",
    "\n",
    "        # if self.output_type == 'binary':\n",
    "        #     out = torch.sigmoid(out)               # Binary prediction\n",
    "        return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11d25ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SimpleGQCNN\n",
    "pose_dims = [0, 1, 2, 3, 4, 5]\n",
    "model = SimpleGQCNN(pose_dim=len(pose_dims), output_type='regression' if use_regression else 'binary')\n",
    "model.load_state_dict(torch.load(\"eps_10/model.pth\", weights_only=True))\n",
    "model = model.to(device, memory_format=torch.channels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f063d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 92.50%\n",
      "ðŸ“Š Confusion Matrix (in %):\n",
      "            Pred 0     Pred 1\n",
      "Actual 0     3.75%     5.62%\n",
      "Actual 1     1.88%    88.75%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.925, [[3.75, 5.625], [1.875, 88.75]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "# Create dataset and dataloader\n",
    "train_loader, val_loader = DexNetDataloader(tensor_dir=tensor_dir, use_regression=use_regression, pose_dims=pose_dims)\n",
    " \n",
    "subset_loader = itertools.islice(val_loader, 5)  # Use only the first 5 batches\n",
    "\n",
    "evaluate_accuracy_with_confusion(model, subset_loader, device, threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
