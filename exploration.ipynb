{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File exploration\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_directory(path):\n",
    "    file_pattern = re.compile(r\"^(.*?)(\\d{5})\\..+$\")  # captures category and 5-digit number\n",
    "    category_files = defaultdict(list)\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        match = file_pattern.match(filename)\n",
    "        if match:\n",
    "            category, number_str = match.groups()\n",
    "            category_files[category].append((filename, int(number_str)))\n",
    "\n",
    "    # Print summary of categories\n",
    "    for category, files in category_files.items():\n",
    "        numbers = [num for _, num in files]\n",
    "        print(f\"Category: {category}\")\n",
    "        print(f\"  Number of files: {len(files)}\")\n",
    "        print(f\"  Number range: {min(numbers)} to {max(numbers)}\")\n",
    "\n",
    "    print(\"\\nInspecting one file per category:\")\n",
    "    for category, files in category_files.items():\n",
    "        sample_file = next(f for f in files if f[0].endswith('.npz'))[0]\n",
    "        filepath = os.path.join(path, sample_file)\n",
    "        print(f\"\\nSample file for category '{category}': {sample_file}\")\n",
    "        try:\n",
    "            data = np.load(filepath)\n",
    "            for key in data:\n",
    "                print(f\"  Key: {key}, Shape: {data[key].shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Could not load file '{sample_file}': {e}\")\n",
    "\n",
    "# Example usage:\n",
    "analyze_directory(\"../dexnet_2.1/dexnet_2.1_eps_10/tensors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Define all categories and their shape descriptions\n",
    "categories = {\n",
    "    'camera_poses_': (1000, 7),\n",
    "    'hand_poses_': (1000, 6),\n",
    "    'depth_ims_tf_table_': (466, 32, 32, 1),\n",
    "    'labels_': (1000,),\n",
    "    'traj_ids_': (1000,),\n",
    "    'grasp_metrics_': (1000,),\n",
    "    'camera_intrs_': (1000, 4),\n",
    "    'grasped_obj_keys_': (1000,),\n",
    "    'grasp_collision_metrics_': (1000,),\n",
    "    'pile_ids_': (1000,)\n",
    "}\n",
    "\n",
    "def load_file(path, category, file_num):\n",
    "    fname = f\"{category}{file_num:05d}.npz\"\n",
    "    fpath = os.path.join(path, fname)\n",
    "    return np.load(fpath)['arr_0']\n",
    "\n",
    "def find_common_file_numbers(path):\n",
    "    files = os.listdir(path)\n",
    "    category_to_nums = {cat: set() for cat in categories}\n",
    "    for fname in files:\n",
    "        for cat in categories:\n",
    "            if fname.startswith(cat) and fname.endswith('.npz'):\n",
    "                try:\n",
    "                    num = int(fname[len(cat):-4])\n",
    "                    category_to_nums[cat].add(num)\n",
    "                except:\n",
    "                    continue\n",
    "    # Find intersection of all sets\n",
    "    common_nums = set.intersection(*category_to_nums.values())\n",
    "    return sorted(list(common_nums))\n",
    "\n",
    "def visualize_random_example(path):\n",
    "    common_files = find_common_file_numbers(path)\n",
    "    if not common_files:\n",
    "        print(\"No common file numbers found across all categories.\")\n",
    "        return\n",
    "\n",
    "    chosen_file_num = random.choice(common_files)\n",
    "\n",
    "    # Load a sample file to determine valid index range\n",
    "    depth_map = load_file(path, 'depth_ims_tf_table_', chosen_file_num)\n",
    "    max_index = depth_map.shape[0]  # Likely 466\n",
    "    chosen_index = random.randint(0, max_index - 1)\n",
    "\n",
    "    print(f\"Selected file number: {chosen_file_num:05d}, sample index: {chosen_index}\\n\")\n",
    "\n",
    "    # Store and print/plot each category\n",
    "    for category in categories:\n",
    "        data = load_file(path, category, chosen_file_num)\n",
    "\n",
    "        if category == 'depth_ims_tf_table_':\n",
    "            image = data[chosen_index].squeeze()\n",
    "            plt.figure()\n",
    "            plt.title(\"Depth Map\")\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "        elif category == 'grasp_metrics_':\n",
    "            plt.figure()\n",
    "            plt.title(\"Grasp Metric (value)\")\n",
    "            plt.bar([0], [data[chosen_index]])\n",
    "            plt.xticks([0], ['Grasp Metric'])\n",
    "            plt.ylabel('Score')\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            print(f\"{category}{chosen_file_num:05d} -> Example[{chosen_index}]: {data[chosen_index]}\\n\")\n",
    "\n",
    "# Example usage\n",
    "# Replace this path with the actual path to your data folder\n",
    "visualize_random_example(\"../dexnet_2.1/dexnet_2.1_eps_10/tensors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd scripts/\n",
    "# ./download_dexnet_2.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['image']['depth_ims']     # Shape: (N, 32, 32)   — depth image\n",
    "dataset['pose']                   # Shape: (N, 4)        — grasp pose (x, y, z, angle)\n",
    "dataset['success']                # Shape: (N,)          — binary label: success/failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For tensorfloaw dataset\n",
    "\"\"\"\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# import h5py\n",
    "# import numpy as np\n",
    "\n",
    "# class DexNetDataset(Dataset):\n",
    "#     def __init__(self, h5_path):\n",
    "#         self.data = h5py.File(h5_path, 'r')\n",
    "#         self.depth_images = self.data['image']['depth_ims'][:]\n",
    "#         self.labels = self.data['grasp_qualities'][:]  # or 'success', depending on file\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.depth_images)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img = self.depth_images[idx]\n",
    "#         img = np.expand_dims(img, axis=0)  # Convert to (1, H, W) for PyTorch CNN\n",
    "#         label = self.labels[idx]\n",
    "#         return torch.tensor(img, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# dataset = DexNetDataset('path/to/dexnet_dataset.h5')\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customize_dataset import DexNetNPZDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = DexNetNPZDataset('../dexnet_2.1/dexnet_2.1_eps_10/tensors/')\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataloader:\n",
    "    print(i[0].shape, i[1])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(32 * 6 * 6, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)  # Binary classification (grasp success)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (B, 16, 15, 15)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (B, 32, 6, 6)\n",
    "        x = x.view(-1, 32 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass and Evaluation Measurements Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "from tqdm import tqdm\n",
    "for epoch in range(3):\n",
    "    for imgs, labels in tqdm(dataloader):\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 15\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for imgs, labels in progress_bar:\n",
    "        outputs = model(imgs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "        # Optional: compute accuracy\n",
    "        predicted = (outputs >= 0.5).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    loss_history.append(epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] — Loss: {epoch_loss:.4f} — Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
